{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as kr\n",
    "from glob import glob\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical # calculate loss function with multiple classes\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.constraints import max_norm #\n",
    "import tensorflow.keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataRename.ipynb', 'DataRescale.ipynb', 'Setup_picture', 'testdata', 'Ausarbeitung', 'DATA', 'RunTB.py', 'sequence_classifier.drawio', 'audio', 'component_diagramm.drawio', 'Roboto', 'plot_confusion_matrix.py', 'Evaluation.ipynb', '.ipynb_checkpoints', 'Confusion_matrix.ipynb', 'Training-Primary.ipynb', 'TimeMeasurement.ipynb', 'statemachine.drawio', 'Filter_Pictures.ipynb', 'TODO', 'README', 'Recording', 'sequence_timer.drawio', '__pycache__', 'convertToTFLITE.ipynb', 'Training-Copy.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSION = (128, 128)\n",
    "DIR_PICS = \"pics/OneSortOfClothes/OneSort/DayNight/\"\n",
    "train_data_dir = DIR_PICS + \"/data/\"\n",
    "val_data_dir = DIR_PICS + \"/val_data/\"\n",
    "nb_train_samples = len(glob('%s/*/*.png' % train_data_dir))\n",
    "nb_classes = len(glob('%s/*/' % train_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1773\n"
     ]
    }
   ],
   "source": [
    "print(nb_classes)\n",
    "print(nb_train_samples)\n",
    "#print(glob('%s/*/' % train_data_dir))\n",
    "\n",
    "#grey UP night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_shift = int(DIMENSION[0]*0.3)\n",
    "height_shift = 0#int(DIMENSION[1]*0.2)\n",
    "flip=True\n",
    "rotation_angle= 10# final rotations will be in the range [-rotation_angle, +rotation_angle]\n",
    "zoom = [0.8, 1.2] #  [lower, upper]\n",
    "shear = 5 # in degrees\n",
    "brightness = [0.1, 1.5]\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=width_shift,\n",
    "    height_shift_range=height_shift,\n",
    "    rotation_range=rotation_angle,\n",
    "    zoom_range=zoom,\n",
    "    shear_range=shear,\n",
    "    horizontal_flip=flip,\n",
    "    brightness_range=brightness)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating into batches and shuffling Data (Used for Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1773 images belonging to 5 classes.\n",
      "Found 212 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batchsize = 32\n",
    "color_mode = 'rgb'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=DIMENSION,\n",
    "        batch_size=batchsize, #Divide the images into baches - 5 means into 5 batches\n",
    "        color_mode=color_mode,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=DIMENSION,\n",
    "        batch_size=1,\n",
    "        color_mode=color_mode,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crooked': 0, 'drinking': 1, 'noperson': 2, 'phone': 3, 'straight': 4}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)\n",
    "\n",
    "##Just for later use\n",
    "#classes = np.array([\"drinking\", \"noperson\", \"crooked\", \"straight\", \"phone\", \"ytvideos\"])\n",
    "#classes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 127, 127, 32)      416       \n",
      "_________________________________________________________________\n",
      "MaxPooling2D_1 (MaxPooling2D (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 60, 60, 64)        32832     \n",
      "_________________________________________________________________\n",
      "MaxPooling2D_2 (MaxPooling2D (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 12, 12, 128)       131200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 312,677\n",
      "Trainable params: 312,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if color_mode == 'grayscale':\n",
    "    DIMENSION_NN = DIMENSION + (1,)\n",
    "elif color_mode == 'rgb':\n",
    "    DIMENSION_NN = DIMENSION + (3,)\n",
    "\n",
    "print(DIMENSION_NN)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# conv block 1\n",
    "model.add(Conv2D(32, kernel_size=(2,2), activation=\"relu\",input_shape=DIMENSION_NN,kernel_constraint=max_norm(3.), name=\"Conv2D_1\")) # single number = biggest difference between two input vectors\n",
    "#model.add(Conv2D(32, kernel_size=(2,2), activation=\"relu\",kernel_constraint=max_norm(3.)))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), name=\"MaxPooling2D_1\"))\n",
    "\n",
    "#conv block 2\n",
    "model.add(Conv2D(64, kernel_size=(4,4),activation=\"relu\", kernel_constraint=max_norm(3.), name=\"Conv2D_2\"))\n",
    "#model.add(Conv2D(64, kernel_size=(3,3),activation=\"relu\", kernel_constraint=max_norm(3.)))\n",
    "model.add(MaxPooling2D(pool_size= (4,4), name=\"MaxPooling2D_2\"))\n",
    "model.add(Dropout(0.5, name=\"Dropout_2\")) # leave random number of weights untouched for a training cycle, here 50%\n",
    "\n",
    "#conv block 3\n",
    "model.add(Conv2D(128, kernel_size=(4,4),activation=\"relu\", kernel_constraint=max_norm(3.)))\n",
    "#model.add(Conv2D(128, kernel_size=(4,4),activation=\"relu\", kernel_constraint=max_norm(3.)))\n",
    "model.add(MaxPooling2D(pool_size= (4,4)))\n",
    "model.add(Dropout(0.5)) # leave random number of weights untouched for a training cycle, here 50%\n",
    "\n",
    "# Identification\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\", name=\"features\"))\n",
    "\n",
    "# last layer to categories\n",
    "model.add(Dense(nb_classes, activation=\"softmax\"))# take the output on the 10 neurons and make a propability distribution\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\"]) #just numbers to evaluate the training process like number of images correcly categorized\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Directory and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_epochs = 30\n",
    "steps=  50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ausarbeitung/NN/keras/Network/kernel_size/OneSort/D_17_H_16_M_28_58725param_32batch_30epoch_AUGset1_combined_kernel_small1773smpl\n"
     ]
    }
   ],
   "source": [
    "# Naming based on the time (to avoid overwriting models) and a buzzword \n",
    "import datetime\n",
    "NN_DIR = \"Ausarbeitung/NN/keras/Network/kernel_size/OneSort/\"\n",
    "DATE = datetime.datetime.now().strftime(\"D_%d_H_%H_M_%M\")\n",
    "ADD_NAME = \"_\" + str(model.count_params()) +\"param_\" + str(batchsize) + \"batch_\" + str(my_epochs) + \"epoch_AUGset1_combined_kernel_small\" + str(nb_train_samples) + \"smpl\"\n",
    "LOGDIR = NN_DIR + DATE + ADD_NAME\n",
    "\n",
    "print(LOGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the acurracy and vaL_acurracy in a graph afterwards\n",
    "my_tensorboard = TensorBoard(log_dir = LOGDIR,\n",
    "                            histogram_freq = 1,\n",
    "                            write_graph = True,\n",
    "                            write_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 1.6106 - accuracy: 0.2188 - val_loss: 1.6080 - val_accuracy: 0.2000\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 1.5682 - accuracy: 0.2929 - val_loss: 1.5438 - val_accuracy: 0.3200\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 1.5242 - accuracy: 0.3042 - val_loss: 1.5341 - val_accuracy: 0.2600\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 31s 611ms/step - loss: 1.4710 - accuracy: 0.3346 - val_loss: 1.3609 - val_accuracy: 0.6200\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 29s 590ms/step - loss: 1.4029 - accuracy: 0.3852 - val_loss: 1.2476 - val_accuracy: 0.5600\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 1.3425 - accuracy: 0.4326 - val_loss: 1.1962 - val_accuracy: 0.7400\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 32s 650ms/step - loss: 1.2828 - accuracy: 0.4541 - val_loss: 1.1340 - val_accuracy: 0.5800\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 32s 639ms/step - loss: 1.2414 - accuracy: 0.4636 - val_loss: 1.1142 - val_accuracy: 0.5800\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 31s 620ms/step - loss: 1.2004 - accuracy: 0.4756 - val_loss: 0.9788 - val_accuracy: 0.6800\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 1.1826 - accuracy: 0.5063 - val_loss: 0.9576 - val_accuracy: 0.6200\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 1.1654 - accuracy: 0.4908 - val_loss: 0.7767 - val_accuracy: 0.7200\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 1.1204 - accuracy: 0.5237 - val_loss: 0.8749 - val_accuracy: 0.6600\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 1.1010 - accuracy: 0.5244 - val_loss: 0.7629 - val_accuracy: 0.7600\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 1.0996 - accuracy: 0.5313 - val_loss: 0.7356 - val_accuracy: 0.6400\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 46s 917ms/step - loss: 1.0790 - accuracy: 0.5566 - val_loss: 0.5639 - val_accuracy: 0.9200\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 47s 932ms/step - loss: 1.0327 - accuracy: 0.5737 - val_loss: 0.5996 - val_accuracy: 0.8000\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 49s 972ms/step - loss: 1.0565 - accuracy: 0.5674 - val_loss: 0.5454 - val_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 48s 955ms/step - loss: 1.0059 - accuracy: 0.5667 - val_loss: 0.8086 - val_accuracy: 0.6400\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 48s 955ms/step - loss: 1.0296 - accuracy: 0.5719 - val_loss: 0.6073 - val_accuracy: 0.7800\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 32s 632ms/step - loss: 0.9800 - accuracy: 0.5870 - val_loss: 0.5324 - val_accuracy: 0.7600\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 0.9456 - accuracy: 0.6123 - val_loss: 0.5142 - val_accuracy: 0.8400\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 32s 646ms/step - loss: 0.9415 - accuracy: 0.6173 - val_loss: 0.6006 - val_accuracy: 0.8400\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 0.9171 - accuracy: 0.6205 - val_loss: 0.3865 - val_accuracy: 0.8400\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 32s 642ms/step - loss: 0.9138 - accuracy: 0.6331 - val_loss: 0.4480 - val_accuracy: 0.7400\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 32s 643ms/step - loss: 0.9036 - accuracy: 0.6350 - val_loss: 0.4168 - val_accuracy: 0.8200\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 0.9135 - accuracy: 0.6293 - val_loss: 0.4204 - val_accuracy: 0.8000\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 33s 661ms/step - loss: 0.8864 - accuracy: 0.6338 - val_loss: 0.4695 - val_accuracy: 0.8400\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 0.8405 - accuracy: 0.6711 - val_loss: 0.4357 - val_accuracy: 0.7800\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 32s 638ms/step - loss: 0.8795 - accuracy: 0.6438 - val_loss: 0.3636 - val_accuracy: 0.9200\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 32s 644ms/step - loss: 0.8668 - accuracy: 0.6224 - val_loss: 0.4065 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=my_epochs,\n",
    "                    steps_per_epoch=steps,\n",
    "                    callbacks=[my_tensorboard], #, tf.keras.callbacks.EarlyStopping(patience=8, verbose=True, restore_best_weights=True)],\n",
    "                    verbose=1,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=steps,\n",
    "                    workers=1,\n",
    "                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(LOGDIR + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RunTB import run_tensorboard\n",
    "run_tensorboard(LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"Ausarbeitung/NN/D_25_H_22_M_02_S_34_front_312kp_32batch_60epoch_combined/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
